{"cells":[{"cell_type":"markdown","metadata":{"id":"NFVxWZGJxprU"},"source":["# CS4001/4042 Assignment 1, Part B, Q2\n","In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network:"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EycCozG06Duu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696573071873,"user_tz":-480,"elapsed":9788,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"9b6c9c15-f9b0-45e7-f188-4247daaa1e38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-widedeep\n","  Downloading pytorch_widedeep-1.3.2-py3-none-any.whl (21.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.5.3)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.11.3)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.2.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.3.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (3.6.1)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.8.0.76)\n","Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (0.5.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (0.15.2+cu118)\n","Collecting einops (from pytorch-widedeep)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (1.15.0)\n","Collecting torchmetrics (from pytorch-widedeep)\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pytorch-widedeep) (9.0.0)\n","Collecting fastparquet>=0.8.1 (from pytorch-widedeep)\n","  Downloading fastparquet-2023.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cramjam>=2.3 (from fastparquet>=0.8.1->pytorch-widedeep)\n","  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (2023.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet>=0.8.1->pytorch-widedeep) (23.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-widedeep) (2023.3.post1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.2.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pytorch-widedeep) (6.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (0.10.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (67.7.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->pytorch-widedeep) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-widedeep) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-widedeep) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-widedeep) (17.0.2)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics->pytorch-widedeep)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pytorch-widedeep) (9.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->pytorch-widedeep) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytorch-widedeep) (2023.7.22)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pytorch-widedeep) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->pytorch-widedeep) (0.1.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy->pytorch-widedeep) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->pytorch-widedeep) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-widedeep) (1.3.0)\n","Installing collected packages: lightning-utilities, einops, cramjam, fastparquet, torchmetrics, pytorch-widedeep\n","Successfully installed cramjam-2.7.0 einops-0.7.0 fastparquet-2023.8.0 lightning-utilities-0.9.0 pytorch-widedeep-1.3.2 torchmetrics-1.2.0\n"]}],"source":["!pip install pytorch-widedeep"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"lq0elU0J53Yo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696573089325,"user_tz":-480,"elapsed":17455,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"de15814b-2cb5-4170-948b-950e6883657a"},"outputs":[{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n","<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"]}],"source":["SEED = 42\n","\n","import os\n","\n","import random\n","random.seed(SEED)\n","\n","import numpy as np\n","np.random.seed(SEED)\n","\n","import pandas as pd\n","\n","from pytorch_widedeep.preprocessing import TabPreprocessor\n","from pytorch_widedeep.models import TabMlp, WideDeep\n","from pytorch_widedeep import Trainer\n","from pytorch_widedeep.metrics import R2Score"]},{"cell_type":"markdown","metadata":{"id":"aU3xdVpwzuLx"},"source":[">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_oYG6lNIh7Mp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696573090018,"user_tz":-480,"elapsed":699,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"597eb77c-e54c-469e-f0ce-a55d86c238b9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["df = pd.read_csv('hdb_price_prediction.csv')\n","\n","# TODO: Enter your code here\n","df = df.drop(['full_address', 'nearest_stn'], axis=1)\n","train = df[df.year <= 2020]\n","test = df[df.year >= 2021]\n"]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COK7YN-QAuam","executionInfo":{"status":"ok","timestamp":1696573090019,"user_tz":-480,"elapsed":7,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"53dd7548-be34-4bab-cd6d-74d6fc68f002"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","metadata":{"id":"m_q9PoR50JAA"},"source":[">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n","https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n","* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n","features and the categorical features. Use this component to transform the training dataset.\n","* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 linear layers in the MLP, with 200 and 100 neurons respectively.\n","* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 100 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"]},{"cell_type":"code","source":["# TODO: Enter your code here\n","# TabPreprocessor\n","continuous_cols = [\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\", \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"]\n","categorical_cols = [ \"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n","\n","tab_preprocessor = TabPreprocessor(\n","    cat_embed_cols=categorical_cols, continuous_cols=continuous_cols\n",")\n","X_tab = tab_preprocessor.fit_transform(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwxLBFVsTEhJ","executionInfo":{"status":"ok","timestamp":1696573090657,"user_tz":-480,"elapsed":642,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"3bb2e9a8-ca4f-4c5e-9d48-bc4ab6c4f4c9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:334: UserWarning: Continuous columns will not be normalised\n","  warnings.warn(\"Continuous columns will not be normalised\")\n"]}]},{"cell_type":"code","source":["# TabMlp\n","tab_mlp = TabMlp(\n","    mlp_hidden_dims=[200, 100],\n","    column_idx=tab_preprocessor.column_idx,\n","    cat_embed_input=tab_preprocessor.cat_embed_input,\n","    continuous_cols=continuous_cols\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OcsPpUCTEj5","executionInfo":{"status":"ok","timestamp":1696573090657,"user_tz":-480,"elapsed":4,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"3ab50ac0-f7f1-4226-8f8e-8673516b5d96"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZBY1iqUXtYWn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696574460339,"user_tz":-480,"elapsed":1369684,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"d64bc7df-361c-40fd-ea68-5fd3df4845ce"},"outputs":[{"output_type":"stream","name":"stderr","text":["epoch 1: 100%|██████████| 1366/1366 [00:27<00:00, 50.02it/s, loss=2.33e+5]\n","epoch 2: 100%|██████████| 1366/1366 [00:13<00:00, 100.16it/s, loss=9.78e+4]\n","epoch 3: 100%|██████████| 1366/1366 [00:13<00:00, 101.87it/s, loss=8.52e+4]\n","epoch 4: 100%|██████████| 1366/1366 [00:13<00:00, 101.72it/s, loss=7.84e+4]\n","epoch 5: 100%|██████████| 1366/1366 [00:12<00:00, 105.66it/s, loss=7.47e+4]\n","epoch 6: 100%|██████████| 1366/1366 [00:13<00:00, 104.67it/s, loss=7.27e+4]\n","epoch 7: 100%|██████████| 1366/1366 [00:13<00:00, 102.96it/s, loss=7.1e+4]\n","epoch 8: 100%|██████████| 1366/1366 [00:15<00:00, 90.99it/s, loss=7e+4]\n","epoch 9: 100%|██████████| 1366/1366 [00:13<00:00, 98.70it/s, loss=6.91e+4] \n","epoch 10: 100%|██████████| 1366/1366 [00:13<00:00, 102.21it/s, loss=6.82e+4]\n","epoch 11: 100%|██████████| 1366/1366 [00:13<00:00, 103.40it/s, loss=6.74e+4]\n","epoch 12: 100%|██████████| 1366/1366 [00:13<00:00, 102.10it/s, loss=6.7e+4]\n","epoch 13: 100%|██████████| 1366/1366 [00:12<00:00, 106.45it/s, loss=6.65e+4]\n","epoch 14: 100%|██████████| 1366/1366 [00:13<00:00, 103.37it/s, loss=6.65e+4]\n","epoch 15: 100%|██████████| 1366/1366 [00:13<00:00, 103.99it/s, loss=6.59e+4]\n","epoch 16: 100%|██████████| 1366/1366 [00:12<00:00, 105.82it/s, loss=6.56e+4]\n","epoch 17: 100%|██████████| 1366/1366 [00:13<00:00, 103.96it/s, loss=6.54e+4]\n","epoch 18: 100%|██████████| 1366/1366 [00:13<00:00, 102.36it/s, loss=6.5e+4]\n","epoch 19: 100%|██████████| 1366/1366 [00:12<00:00, 105.95it/s, loss=6.49e+4]\n","epoch 20: 100%|██████████| 1366/1366 [00:13<00:00, 103.77it/s, loss=6.46e+4]\n","epoch 21: 100%|██████████| 1366/1366 [00:13<00:00, 101.07it/s, loss=6.46e+4]\n","epoch 22: 100%|██████████| 1366/1366 [00:13<00:00, 102.95it/s, loss=6.42e+4]\n","epoch 23: 100%|██████████| 1366/1366 [00:13<00:00, 102.43it/s, loss=6.43e+4]\n","epoch 24: 100%|██████████| 1366/1366 [00:13<00:00, 100.71it/s, loss=6.38e+4]\n","epoch 25: 100%|██████████| 1366/1366 [00:13<00:00, 99.38it/s, loss=6.37e+4] \n","epoch 26: 100%|██████████| 1366/1366 [00:13<00:00, 101.03it/s, loss=6.36e+4]\n","epoch 27: 100%|██████████| 1366/1366 [00:13<00:00, 101.94it/s, loss=6.35e+4]\n","epoch 28: 100%|██████████| 1366/1366 [00:13<00:00, 103.42it/s, loss=6.33e+4]\n","epoch 29: 100%|██████████| 1366/1366 [00:13<00:00, 101.75it/s, loss=6.31e+4]\n","epoch 30: 100%|██████████| 1366/1366 [00:13<00:00, 101.87it/s, loss=6.27e+4]\n","epoch 31: 100%|██████████| 1366/1366 [00:13<00:00, 103.61it/s, loss=6.28e+4]\n","epoch 32: 100%|██████████| 1366/1366 [00:13<00:00, 102.26it/s, loss=6.25e+4]\n","epoch 33: 100%|██████████| 1366/1366 [00:13<00:00, 102.12it/s, loss=6.24e+4]\n","epoch 34: 100%|██████████| 1366/1366 [00:13<00:00, 101.89it/s, loss=6.22e+4]\n","epoch 35: 100%|██████████| 1366/1366 [00:13<00:00, 102.59it/s, loss=6.22e+4]\n","epoch 36: 100%|██████████| 1366/1366 [00:13<00:00, 101.38it/s, loss=6.21e+4]\n","epoch 37: 100%|██████████| 1366/1366 [00:13<00:00, 104.45it/s, loss=6.2e+4]\n","epoch 38: 100%|██████████| 1366/1366 [00:13<00:00, 103.77it/s, loss=6.18e+4]\n","epoch 39: 100%|██████████| 1366/1366 [00:13<00:00, 102.59it/s, loss=6.15e+4]\n","epoch 40: 100%|██████████| 1366/1366 [00:12<00:00, 106.47it/s, loss=6.16e+4]\n","epoch 41: 100%|██████████| 1366/1366 [00:13<00:00, 102.75it/s, loss=6.12e+4]\n","epoch 42: 100%|██████████| 1366/1366 [00:13<00:00, 100.16it/s, loss=6.11e+4]\n","epoch 43: 100%|██████████| 1366/1366 [00:13<00:00, 101.68it/s, loss=6.1e+4]\n","epoch 44: 100%|██████████| 1366/1366 [00:14<00:00, 95.99it/s, loss=6.09e+4] \n","epoch 45: 100%|██████████| 1366/1366 [00:13<00:00, 103.97it/s, loss=6.06e+4]\n","epoch 46: 100%|██████████| 1366/1366 [00:13<00:00, 103.02it/s, loss=6.07e+4]\n","epoch 47: 100%|██████████| 1366/1366 [00:13<00:00, 102.18it/s, loss=6.04e+4]\n","epoch 48: 100%|██████████| 1366/1366 [00:13<00:00, 99.67it/s, loss=6.03e+4] \n","epoch 49: 100%|██████████| 1366/1366 [00:13<00:00, 101.72it/s, loss=6.01e+4]\n","epoch 50: 100%|██████████| 1366/1366 [00:13<00:00, 104.54it/s, loss=6.01e+4]\n","epoch 51: 100%|██████████| 1366/1366 [00:13<00:00, 104.66it/s, loss=5.99e+4]\n","epoch 52: 100%|██████████| 1366/1366 [00:13<00:00, 103.83it/s, loss=5.96e+4]\n","epoch 53: 100%|██████████| 1366/1366 [00:13<00:00, 100.52it/s, loss=5.97e+4]\n","epoch 54: 100%|██████████| 1366/1366 [00:13<00:00, 101.93it/s, loss=5.94e+4]\n","epoch 55: 100%|██████████| 1366/1366 [00:13<00:00, 98.61it/s, loss=5.93e+4] \n","epoch 56: 100%|██████████| 1366/1366 [00:13<00:00, 102.08it/s, loss=5.92e+4]\n","epoch 57: 100%|██████████| 1366/1366 [00:13<00:00, 98.43it/s, loss=5.91e+4] \n","epoch 58: 100%|██████████| 1366/1366 [00:13<00:00, 102.65it/s, loss=5.92e+4]\n","epoch 59: 100%|██████████| 1366/1366 [00:13<00:00, 103.59it/s, loss=5.89e+4]\n","epoch 60: 100%|██████████| 1366/1366 [00:13<00:00, 101.67it/s, loss=5.88e+4]\n","epoch 61: 100%|██████████| 1366/1366 [00:14<00:00, 94.20it/s, loss=5.85e+4]\n","epoch 62: 100%|██████████| 1366/1366 [00:13<00:00, 101.90it/s, loss=5.85e+4]\n","epoch 63: 100%|██████████| 1366/1366 [00:13<00:00, 100.76it/s, loss=5.83e+4]\n","epoch 64: 100%|██████████| 1366/1366 [00:13<00:00, 102.36it/s, loss=5.85e+4]\n","epoch 65: 100%|██████████| 1366/1366 [00:13<00:00, 101.29it/s, loss=5.8e+4]\n","epoch 66: 100%|██████████| 1366/1366 [00:13<00:00, 101.54it/s, loss=5.79e+4]\n","epoch 67: 100%|██████████| 1366/1366 [00:13<00:00, 101.14it/s, loss=5.75e+4]\n","epoch 68: 100%|██████████| 1366/1366 [00:13<00:00, 100.48it/s, loss=5.73e+4]\n","epoch 69: 100%|██████████| 1366/1366 [00:13<00:00, 100.20it/s, loss=5.68e+4]\n","epoch 70: 100%|██████████| 1366/1366 [00:13<00:00, 103.27it/s, loss=5.64e+4]\n","epoch 71: 100%|██████████| 1366/1366 [00:13<00:00, 97.90it/s, loss=5.57e+4]\n","epoch 72: 100%|██████████| 1366/1366 [00:13<00:00, 101.54it/s, loss=5.51e+4]\n","epoch 73: 100%|██████████| 1366/1366 [00:13<00:00, 100.06it/s, loss=5.42e+4]\n","epoch 74: 100%|██████████| 1366/1366 [00:14<00:00, 97.49it/s, loss=5.37e+4] \n","epoch 75: 100%|██████████| 1366/1366 [00:14<00:00, 94.22it/s, loss=5.3e+4]\n","epoch 76: 100%|██████████| 1366/1366 [00:13<00:00, 98.34it/s, loss=5.27e+4]\n","epoch 77: 100%|██████████| 1366/1366 [00:13<00:00, 101.66it/s, loss=5.23e+4]\n","epoch 78: 100%|██████████| 1366/1366 [00:13<00:00, 99.91it/s, loss=5.21e+4] \n","epoch 79: 100%|██████████| 1366/1366 [00:14<00:00, 95.22it/s, loss=5.19e+4]\n","epoch 80: 100%|██████████| 1366/1366 [00:13<00:00, 101.61it/s, loss=5.17e+4]\n","epoch 81: 100%|██████████| 1366/1366 [00:13<00:00, 100.47it/s, loss=5.17e+4]\n","epoch 82: 100%|██████████| 1366/1366 [00:13<00:00, 102.47it/s, loss=5.15e+4]\n","epoch 83: 100%|██████████| 1366/1366 [00:14<00:00, 96.15it/s, loss=5.13e+4] \n","epoch 84: 100%|██████████| 1366/1366 [00:13<00:00, 100.54it/s, loss=5.12e+4]\n","epoch 85: 100%|██████████| 1366/1366 [00:13<00:00, 101.44it/s, loss=5.08e+4]\n","epoch 86: 100%|██████████| 1366/1366 [00:13<00:00, 99.87it/s, loss=5.08e+4] \n","epoch 87: 100%|██████████| 1366/1366 [00:13<00:00, 102.31it/s, loss=5.08e+4]\n","epoch 88: 100%|██████████| 1366/1366 [00:13<00:00, 99.28it/s, loss=5.08e+4]\n","epoch 89: 100%|██████████| 1366/1366 [00:13<00:00, 98.98it/s, loss=5.07e+4]\n","epoch 90: 100%|██████████| 1366/1366 [00:13<00:00, 100.44it/s, loss=5.07e+4]\n","epoch 91: 100%|██████████| 1366/1366 [00:13<00:00, 100.90it/s, loss=5.05e+4]\n","epoch 92: 100%|██████████| 1366/1366 [00:13<00:00, 99.82it/s, loss=5.03e+4] \n","epoch 93: 100%|██████████| 1366/1366 [00:14<00:00, 97.24it/s, loss=5.04e+4] \n","epoch 94: 100%|██████████| 1366/1366 [00:13<00:00, 100.42it/s, loss=5.05e+4]\n","epoch 95: 100%|██████████| 1366/1366 [00:13<00:00, 100.28it/s, loss=5.02e+4]\n","epoch 96: 100%|██████████| 1366/1366 [00:13<00:00, 97.82it/s, loss=5.02e+4]\n","epoch 97: 100%|██████████| 1366/1366 [00:14<00:00, 96.32it/s, loss=5e+4]\n","epoch 98: 100%|██████████| 1366/1366 [00:13<00:00, 102.54it/s, loss=4.98e+4]\n","epoch 99: 100%|██████████| 1366/1366 [00:13<00:00, 98.59it/s, loss=5e+4] \n","epoch 100: 100%|██████████| 1366/1366 [00:13<00:00, 98.42it/s, loss=5e+4] \n"]}],"source":["model = WideDeep(deeptabular=tab_mlp)\n","# Trainer\n","trainer = Trainer(model, objective=\"rmse\", num_workers=0)\n","trainer.fit(\n","    X_tab=X_tab,\n","    target=train['resale_price'].values,\n","    n_epochs=100,\n","    batch_size=64,\n",")"]},{"cell_type":"code","source":["# Saving the model\n","import torch\n","torch.save(model.state_dict(), \"model.pt\")"],"metadata":{"id":"3d4OjbQkWuy1","executionInfo":{"status":"ok","timestamp":1696574460339,"user_tz":-480,"elapsed":24,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Loading the model\n","load_model = WideDeep(deeptabular=tab_mlp)\n","load_model.load_state_dict(torch.load(\"model.pt\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_k3dgfaW1eN","executionInfo":{"status":"ok","timestamp":1696574460339,"user_tz":-480,"elapsed":10,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"f56f4acf-10d6-44c9-8166-60ad14ee0159"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Test\n","X_tab_test = tab_preprocessor.transform(test)\n","preds = trainer.predict(X_tab=X_tab_test, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTQ0TMOyTCTZ","executionInfo":{"status":"ok","timestamp":1696574465377,"user_tz":-480,"elapsed":5043,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"b32f030e-3c99-4cb9-db72-e7b70e3a7a18"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["predict: 100%|██████████| 1128/1128 [00:04<00:00, 232.13it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"V46s-MdM0y5c"},"source":[">Report the test RMSE and the test R2 value that you obtained."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"KAhAgvMC07g6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696574465378,"user_tz":-480,"elapsed":24,"user":{"displayName":"haoyi gan","userId":"15305064828944639006"}},"outputId":"574c419a-8b51-43f9-84ad-a31afe57bee6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["RMSE: 97305.52473036667\n","R Squared: 0.6691938856757513\n"]}],"source":["# TODO: Enter your code here\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# print(f\"preds: {len(preds)}\")\n","y = test['resale_price'].values.tolist()\n","# print(f\"y: {len(y)}\")\n","mse = np.sqrt(mean_squared_error(y, preds))\n","rsquared = r2_score(y, preds)\n","print(f\"RMSE: {mse}\")\n","print(f\"R Squared: {rsquared}\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}