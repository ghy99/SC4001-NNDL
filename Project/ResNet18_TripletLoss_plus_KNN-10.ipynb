{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "This file contains the ResNet18 model where we used Triplet Loss on the model, then we combined it with a K-Nearest Neighbour Classifier to classify the images. \n",
    "\n",
    "The idea is that we learn the image embeddings based on the distance metric from the anchor to positive and anchor to negative. After the model learns the similarity between images, we try to classify the images based on similarity of the test images to the trained KNN Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::anyio==3.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::argon2-cffi==23.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::argon2-cffi-bindings==21.2.0=py310h5764c6d_2\n",
      "  - conda-forge/noarch::asttokens==2.4.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::attrs==23.1.0=pyh71513ae_1\n",
      "  - conda-forge/noarch::backcall==0.2.0=pyh9f0ad1d_0\n",
      "  - conda-forge/noarch::backports==1.0=pyhd8ed1ab_3\n",
      "  - conda-forge/noarch::backports.functools_lru_cache==1.6.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::beautifulsoup4==4.12.2=pyha770c72_0\n",
      "  - conda-forge/noarch::bleach==6.1.0=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::bzip2==1.0.8=h7b6447c_0\n",
      "  - defaults/linux-64::cffi==1.15.1=py310h5eee18b_3\n",
      "  - conda-forge/noarch::comm==0.1.4=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::debugpy==1.6.7=py310h6a678d5_0\n",
      "  - conda-forge/noarch::decorator==5.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::defusedxml==0.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::entrypoints==0.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::exceptiongroup==1.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::executing==2.0.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::idna==3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_resources==6.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::ipykernel==6.14.0=py310hfdc917e_0\n",
      "  - conda-forge/linux-64::ipython==8.4.0=py310hff52083_0\n",
      "  - conda-forge/noarch::ipython_genutils==0.2.0=py_1\n",
      "  - conda-forge/noarch::ipywidgets==8.1.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jedi==0.19.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jinja2==3.1.2=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::jsonschema==4.19.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jsonschema-specifications==2023.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter==1.0.0=pyhd8ed1ab_10\n",
      "  - conda-forge/noarch::jupyterlab_pygments==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_widgets==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_client==7.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_console==6.6.3=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter_core==5.5.0=py310hff52083_0\n",
      "  - conda-forge/noarch::jupyter_server==1.24.0=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::libffi==3.4.4=h6a678d5_0\n",
      "  - defaults/linux-64::libgcc-ng==11.2.0=h1234567_1\n",
      "  - conda-forge/linux-64::libsodium==1.0.18=h36c2ea0_1\n",
      "  - defaults/linux-64::libstdcxx-ng==11.2.0=h1234567_1\n",
      "  - defaults/linux-64::libuuid==1.41.5=h5eee18b_0\n",
      "  - defaults/linux-64::markupsafe==2.1.1=py310h7f8727e_0\n",
      "  - conda-forge/noarch::matplotlib-inline==0.1.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::mistune==3.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclassic==1.0.0=pyhb4ecaf3_1\n",
      "  - conda-forge/noarch::nbclient==0.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert==7.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==7.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbformat==5.9.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nb_conda_kernels==2.3.1=py310hff52083_2\n",
      "  - defaults/linux-64::ncurses==6.4=h6a678d5_0\n",
      "  - conda-forge/noarch::nest-asyncio==1.5.8=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==6.5.6=pyha770c72_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.3=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::openssl==3.0.12=h7f8727e_0\n",
      "  - conda-forge/noarch::packaging==23.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pandocfilters==1.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::parso==0.8.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pexpect==4.8.0=pyh1a96a4e_2\n",
      "  - conda-forge/noarch::pickleshare==0.7.5=py_1003\n",
      "  - defaults/linux-64::pip==23.3=py310h06a4308_0\n",
      "  - conda-forge/noarch::pkgutil-resolve-name==1.3.10=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::platformdirs==3.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prometheus_client==0.18.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::prompt-toolkit==3.0.39=pyha770c72_0\n",
      "  - conda-forge/noarch::prompt_toolkit==3.0.39=hd8ed1ab_0\n",
      "  - defaults/linux-64::psutil==5.9.0=py310h5eee18b_0\n",
      "  - conda-forge/noarch::ptyprocess==0.7.0=pyhd3deb0d_0\n",
      "  - conda-forge/noarch::pure_eval==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pycparser==2.21=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pygments==2.16.1=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::python==3.10.13=h955ad1f_0\n",
      "  - conda-forge/noarch::python-dateutil==2.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-fastjsonschema==2.18.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::python_abi==3.10=2_cp310\n",
      "  - defaults/linux-64::pyzmq==23.2.0=py310h6a678d5_0\n",
      "  - conda-forge/noarch::qtconsole-base==5.5.0=pyha770c72_0\n",
      "  - conda-forge/noarch::qtpy==2.4.1=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::readline==8.2=h5eee18b_0\n",
      "  - conda-forge/noarch::referencing==0.30.2=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::rpds-py==0.10.6=py310hb02cf49_0\n",
      "  - defaults/noarch::send2trash==1.8.0=pyhd3eb1b0_1\n",
      "  - defaults/linux-64::setuptools==68.0.0=py310h06a4308_0\n",
      "  - conda-forge/noarch::six==1.16.0=pyh6c4a22f_0\n",
      "  - conda-forge/noarch::sniffio==1.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::soupsieve==2.5=pyhd8ed1ab_1\n",
      "  - defaults/linux-64::sqlite==3.41.2=h5eee18b_0\n",
      "  - conda-forge/noarch::stack_data==0.6.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::terminado==0.15.0=py310hff52083_0\n",
      "  - conda-forge/noarch::tinycss2==1.2.1=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::tk==8.6.12=h1ccaba5_0\n",
      "  - conda-forge/linux-64::tornado==6.1=py310h5764c6d_3\n",
      "  - conda-forge/noarch::traitlets==5.13.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::typing-extensions==4.8.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::typing_extensions==4.8.0=pyha770c72_0\n",
      "  - conda-forge/noarch::wcwidth==0.2.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::webencodings==0.5.1=pyhd8ed1ab_2\n",
      "  - conda-forge/noarch::websocket-client==1.6.4=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::wheel==0.41.2=py310h06a4308_0\n",
      "  - conda-forge/noarch::widgetsnbextension==4.0.9=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::xz==5.4.2=h5eee18b_0\n",
      "  - defaults/linux-64::zeromq==4.3.4=h2531618_0\n",
      "  - conda-forge/noarch::zipp==3.17.0=pyhd8ed1ab_0\n",
      "  - defaults/linux-64::zlib==1.2.13=h5eee18b_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/UG/ganh0018/.conda/envs/venv\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.10\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.7.2~ --> pkgs/main::ca-certificates-2023.08.22-h06a4308_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!conda install -y python=3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.18.1\n",
      "Uninstalling numpy-1.18.1:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 566, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/apps/anaconda3/bin/f2py' -> '/tmp/pip-uninstall-asmb2mrl/f2py'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/uninstall.py\", line 79, in run\n",
      "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 687, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 394, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 283, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 334, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 581, in move\n",
      "    os.unlink(src)\n",
      "PermissionError: [Errno 13] Permission denied: '/apps/anaconda3/bin/f2py'\u001b[0m\n",
      "Found existing installation: torch 1.6.0\n",
      "Uninstalling torch-1.6.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 566, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/apps/anaconda3/bin/convert-caffe2-to-onnx' -> '/tmp/pip-uninstall-ghip6gs_/convert-caffe2-to-onnx'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/uninstall.py\", line 79, in run\n",
      "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 687, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 394, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 283, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 334, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 581, in move\n",
      "    os.unlink(src)\n",
      "PermissionError: [Errno 13] Permission denied: '/apps/anaconda3/bin/convert-caffe2-to-onnx'\u001b[0m\n",
      "Found existing installation: torchvision 0.7.0\n",
      "Uninstalling torchvision-0.7.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 566, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/apps/anaconda3/lib/python3.7/site-packages/torchvision' -> '/tmp/pip-uninstall-v5srse7z'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/uninstall.py\", line 79, in run\n",
      "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 687, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 394, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/req/req_uninstall.py\", line 283, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/apps/anaconda3/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 334, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 578, in move\n",
      "    rmtree(src)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 494, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 432, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 452, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/apps/anaconda3/lib/python3.7/shutil.py\", line 450, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'caltech.py'\u001b[0m\n",
      "Found existing installation: jupyter 1.0.0\n",
      "Uninstalling jupyter-1.0.0:\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip uninstall -y torch\n",
    "!pip uninstall -y torchvision\n",
    "!pip uninstall -y jupyter\n",
    "!pip uninstall -y matplotlib\n",
    "!pip uninstall -y pandas\n",
    "!pip uninstall -y scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /apps/anaconda3/lib/python3.7/site-packages (1.18.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /apps/anaconda3/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: future in /apps/anaconda3/lib/python3.7/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in /apps/anaconda3/lib/python3.7/site-packages (from torch) (1.18.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /apps/anaconda3/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /apps/anaconda3/lib/python3.7/site-packages (from torchvision) (1.18.1)\n",
      "Requirement already satisfied: torch in /apps/anaconda3/lib/python3.7/site-packages (from torchvision) (1.6.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /apps/anaconda3/lib/python3.7/site-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: future in /apps/anaconda3/lib/python3.7/site-packages (from torch->torchvision) (0.18.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jupyter in /apps/anaconda3/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (7.5.1)\n",
      "Requirement already satisfied: nbconvert in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (5.6.1)\n",
      "Requirement already satisfied: ipykernel in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (5.1.4)\n",
      "Requirement already satisfied: qtconsole in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (4.6.0)\n",
      "Requirement already satisfied: jupyter-console in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (6.1.0)\n",
      "Requirement already satisfied: notebook in /apps/anaconda3/lib/python3.7/site-packages (from jupyter) (6.0.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /apps/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /apps/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /apps/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter) (7.12.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /apps/anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter) (5.0.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: testpath in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: pygments in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (2.5.2)\n",
      "Requirement already satisfied: defusedxml in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (2.11.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: jupyter-core in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (4.6.1)\n",
      "Requirement already satisfied: bleach in /apps/anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /apps/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in /apps/anaconda3/lib/python3.7/site-packages (from ipykernel->jupyter) (5.3.4)\n",
      "Requirement already satisfied: ipython-genutils in /apps/anaconda3/lib/python3.7/site-packages (from qtconsole->jupyter) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /apps/anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter) (3.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /apps/anaconda3/lib/python3.7/site-packages (from notebook->jupyter) (18.1.1)\n",
      "Requirement already satisfied: Send2Trash in /apps/anaconda3/lib/python3.7/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /apps/anaconda3/lib/python3.7/site-packages (from notebook->jupyter) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /apps/anaconda3/lib/python3.7/site-packages (from notebook->jupyter) (0.7.1)\n",
      "Requirement already satisfied: six in /apps/anaconda3/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets->jupyter) (1.14.0)\n",
      "Requirement already satisfied: decorator in /apps/anaconda3/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets->jupyter) (4.4.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /apps/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (45.2.0.post20200210)\n",
      "Requirement already satisfied: backcall in /apps/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /apps/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pickleshare in /apps/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /apps/anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (4.8.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /apps/anaconda3/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /apps/anaconda3/lib/python3.7/site-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
      "Requirement already satisfied: webencodings in /apps/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /apps/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter) (2.8.1)\n",
      "Requirement already satisfied: wcwidth in /apps/anaconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter) (0.1.8)\n",
      "Requirement already satisfied: parso>=0.5.0 in /apps/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.5.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /apps/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter) (0.6.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /apps/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /apps/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /apps/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /apps/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /apps/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter) (2.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /apps/anaconda3/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /apps/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in /apps/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.1 in /apps/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /apps/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /apps/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /apps/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /apps/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /apps/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /apps/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /apps/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /apps/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /apps/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /apps/anaconda3/lib/python3.7/site-packages (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /apps/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /apps/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /apps/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install jupyter\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import scipy\n",
    "from torch.autograd import Variable\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aaadcad45f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms and regular dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a triplet dataset for Flowers 102\n",
    "\n",
    "In this function, we are manipulating the flowers102 dataset to return the inputs in order of 3 for each data point. \n",
    "\n",
    "We arrange the data points to have the format of `(anchor image, positive image, negative image)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.datasets' has no attribute 'flowers102'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8f61d66f57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNewFlowers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflowers102\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlowers102\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   def __init__(\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.datasets' has no attribute 'flowers102'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Tuple, Callable, Optional\n",
    "import random\n",
    "import PIL.Image\n",
    "\n",
    "class NewFlowers(torchvision.datasets.flowers102.Flowers102):\n",
    "  def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        split: str = \"train\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "    super().__init__(root, split, transform, target_transform, download)\n",
    "    self._labels = np.array(self._labels, dtype=\"int\")\n",
    "    \n",
    "  def __getitem__(self, item):\n",
    "    # Obtain indexes of all the labels\n",
    "    index = np.array(list(range(0, len(self._labels))), dtype=\"int\")\n",
    "    \n",
    "    # Obtain anchor image \n",
    "    anchor_img = self._image_files[item]\n",
    "    anchor_img = PIL.Image.open(anchor_img).convert(\"RGB\")\n",
    "    \n",
    "    # Obtain anchor label\n",
    "    anchor_label = self._labels[item]\n",
    "\n",
    "    # Generate positive index list where it is not the same class as the anchor\n",
    "    positive_list = index[index!=item][self._labels[index!=item]==anchor_label]\n",
    "    \n",
    "    # Randomly obtain 1 positive item and its respective image\n",
    "    positive_item = random.choice(positive_list)\n",
    "    positive_img = self._image_files[positive_item]\n",
    "    positive_img = PIL.Image.open(positive_img).convert(\"RGB\")\n",
    "\n",
    "    # Generate negative index list where it is not the same class as the anchor\n",
    "    negative_list = index[index!=item][self._labels[index!=item]!=anchor_label]\n",
    "    \n",
    "    # Randomly obtain 1 negative item and its respective image\n",
    "    negative_item = random.choice(negative_list)\n",
    "    negative_img = self._image_files[negative_item]\n",
    "    negative_img = PIL.Image.open(negative_img).convert(\"RGB\")\n",
    "\n",
    "    # Apply transformation on images\n",
    "    anchor_img = self.transform(anchor_img)\n",
    "    positive_img = self.transform(positive_img)\n",
    "    negative_img = self.transform(negative_img)\n",
    "\n",
    "    return (anchor_img, positive_img, negative_img), anchor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triplet_train = NewFlowers(\"./train\", split=\"train\", download=True, transform=data_transforms[\"train\"])\n",
    "triplet_val = NewFlowers(\"./train\", split=\"val\", download=False, transform=data_transforms[\"val\"])\n",
    "triplet_test = NewFlowers(\"./train\", split=\"test\", download=False, transform=data_transforms[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the dataset in dataloaders, with batch size 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_train_dataloader = torch.utils.data.DataLoader(triplet_train, batch_size=4, shuffle=True)\n",
    "triplet_val_dataloader = torch.utils.data.DataLoader(triplet_val, batch_size=4, shuffle=True)\n",
    "triplet_test_dataloader = torch.utils.data.DataLoader(triplet_test, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': triplet_train,\n",
    "    'val': triplet_val,\n",
    "    'test': triplet_test\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": triplet_train_dataloader,\n",
    "    \"val\": triplet_val_dataloader,\n",
    "    \"test\": triplet_test_dataloader,\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(dataloaders[x].dataset)\n",
    "    for x in list(image_datasets.keys())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our triplet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor, positive, negative = 0,0,0\n",
    "for i, (inputs, labels) in enumerate(triplet_train_dataloader):\n",
    "#     print(labels)\n",
    "    anchor, positive, negative = inputs\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_out = torchvision.utils.make_grid(anchor)\n",
    "imshow(anchor_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_out = torchvision.utils.make_grid(positive)\n",
    "imshow(positive_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_out = torchvision.utils.make_grid(negative)\n",
    "imshow(negative_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function to train the model.\n",
    "We are using both `Triplet Loss` & `Cross Entropy Loss`. \n",
    "\n",
    "We pass the `anchor image`, `positive image`, and `negative image` into the `Triplet Loss` function to get the loss for the similarity between `anchor and positive image` and `anchor and negative image`. \n",
    "\n",
    "We then pass the prediction of the anchor image with its label into the `Cross Entropy Loss` function to get the loss between prediction and target label. \n",
    "\n",
    "Now, we add the 2 losses together as a weighted sum for the loss. We use this weighted sum of loss for the model to learn its weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    checkpoint_path = './model_checkpoints'\n",
    "    train_loss, train_acc = [], []\n",
    "    val_loss, val_acc = [], []\n",
    " \n",
    "    best_model_params_path = os.path.join(checkpoint_path, 't_resnet_triplet_loss_plus_knn.pt')\n",
    "\n",
    "    torch.save(model, best_model_params_path)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    #this is to be used later\n",
    "    crossEntropyLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for step, (inputs, anchor_label) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                anchor_label = anchor_label.to(device)\n",
    "                \n",
    "                # Here, we load the 3 images from inputs into 3 variables, the anchor, positive image, and negative image. \n",
    "                anchor_img, positive_img, negative_img = inputs\n",
    "                anchor_img = anchor_img.to(device)\n",
    "                positive_img = positive_img.to(device)\n",
    "                negative_img = negative_img.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # We passed the 3 images through the model to get the embedding of the image. \n",
    "                    anchor_out = model(anchor_img)\n",
    "                    positive_out = model(positive_img)\n",
    "                    negative_out = model(negative_img)\n",
    "                    \n",
    "                    _, preds = torch.max(anchor_out, 1)\n",
    "\n",
    "                    preds = preds.to(device)\n",
    "                    \n",
    "                    # This is from tripletLoss (class labels not involved in loss calculation)\n",
    "                    loss = criterion(anchor_out, positive_out, negative_out) \n",
    "\n",
    "                    # In order to incorporate meaning to the loss, \n",
    "                    # We experiment adding Cross Entropy Loss as class labels are involved in loss calculation\n",
    "                    celoss = crossEntropyLoss(anchor_out, anchor_label)\n",
    "                    \n",
    "                    # We then add the Cross Entropy Loss and Triplet Loss together. \n",
    "                    loss += celoss\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * len(anchor_label)\n",
    "                running_corrects += torch.sum(preds == anchor_label.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "            print(f'{phase} Loss:\\t{epoch_loss:.4f}\\tAcc:\\t{epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            elif phase == 'val':\n",
    "                val_loss.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "                \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}\\n')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model, train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot train & val accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(no_epoch, train, val, title):\n",
    "    plt.figure()\n",
    "    plt.plot(range(no_epoch), train, label='train')\n",
    "    plt.plot(range(no_epoch), val, label='val')\n",
    "    if \"Accuracy\" in title:\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "    elif \"Loss\" in title:\n",
    "        plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning (ResNet18)\n",
    "\n",
    "In the cell below, we load the model. \n",
    "If the model weights do not exist yet, we will download the weights from `IMAGENET1K_V1` from the ResNet18 model, \n",
    "and load these weights into our `ResNet18` model. We then change the last fully connected layer into a layer with 102 neurons, each representing a class. \n",
    "\n",
    "We will be using `Cross Entropy Loss function`, `Triplet Loss function`, `SGD Optimizer` with a `learning rate of 0.001` and a `momentum of 0.9`.\n",
    "The step scheduler will not affect training as we set the step to 200 epochs while we are only using `100 epochs`. \n",
    "This is because we want to let the model learn. \n",
    "In the previous setting of `step = 7`, the model could not learn well enough, resulting in an accuracy of <35%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model_checkpoints/resnet_triplet_loss_plus_knn.pt'\n",
    "\n",
    "check_file = os.path.exists(model_path)\n",
    "if check_file:\n",
    "    print(f\"Loading model from checkpoint\")\n",
    "    model = torch.load(model_path)\n",
    "    \n",
    "else:\n",
    "    print(f\"Model checkpoint does not exist.\\nDownloading new model...\")\n",
    "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 102)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model = model.to(device)\n",
    "# model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=200, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the number of epochs = 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, train_loss, train_acc, val_loss, val_acc = train_model(model, optimizer, criterion, exp_lr_scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we preprocess our dataset in preparation for the K-Nearest Neighbour Classifier. \n",
    "\n",
    "We pass the images from train and validation through the model while enabling `no_grad()`. \n",
    "After passing the images through the model, we get the image embedding of shape (102, ). \n",
    "We then use these embeddings to train the KNN Classifier. \n",
    "\n",
    "The idea is that we train the KNN Classifier on the embeddings to learn the clusters of the training and validation. Then, we pass the test data embeddings through the classifier to see what their nearest neighbours are, and classify them based on this idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_knn(model, phases):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    # fig = plt.figure()\n",
    "    # size = len(dataloaders['train'].dataset)\n",
    "    # no_batches = len(dataloaders['train'])\n",
    "    # correct = 0\n",
    "\n",
    "    # This is my embeddings of the training images.\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for phase in phases:\n",
    "            for i, (inputs, anchor_label) in enumerate(dataloaders[phase]):\n",
    "                anchor_label = anchor_label.to(device)\n",
    "                anchor_img, _, _ = inputs\n",
    "                anchor_img = anchor_img.to(device)\n",
    "\n",
    "                anchor_out = model(anchor_img)\n",
    "                for i in range(len(anchor_out)):\n",
    "                    X.append(anchor_out[i])\n",
    "                    y.append(anchor_label[i])\n",
    "\n",
    "    #         _, preds = torch.max(anchor_out, 1)\n",
    "\n",
    "    #         preds = preds.to(device)\n",
    "\n",
    "    #         correct += torch.sum(preds == anchor_label.data)\n",
    "    #         if i % 20 == 0:\n",
    "    #             print(f'Predicted: {preds[0]} | True: {anchor_label[0]}')\n",
    "\n",
    "    # correct = correct.double() / size\n",
    "    model.train(mode=was_training)\n",
    "\n",
    "    for x in range(len(X)):\n",
    "        X[x] = X[x].cpu().detach().numpy()\n",
    "        \n",
    "    for x in range(len(y)):\n",
    "        y[x] = y[x].cpu().detach().numpy()\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = preprocess_knn(model, ['train', 'val'])\n",
    "X_test, y_test = preprocess_knn(model, ['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of the KNN classifier is around 80.11%. \n",
    "\n",
    "The model performed significantly better than the ResNet18 models with deformed convolution. \n",
    "\n",
    "However, it performed slightly worse than the original ResNet18 model (87.27%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(preds, target):\n",
    "#     for i in range(len(preds)):\n",
    "    score = np.sum(preds == target)\n",
    "    score /= len(preds)\n",
    "    return score\n",
    "\n",
    "preds = knn.predict(X_test)\n",
    "acc = calc_acc(preds, y_test)\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model directly, instead of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"targets: {y_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting our train/val to lists of float values (currently tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_epochs):\n",
    "    train_acc[i] = train_acc[i].cpu()\n",
    "    val_acc[i] = val_acc[i].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(num_epochs, train_acc, val_acc, \"Epoch vs Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(num_epochs, train_loss, val_loss, \"Epoch vs Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we decided to test the model with only Cross Entropy Loss and Triplet Loss without the KNN Classifier. \n",
    "The model returned a result of 83.25%. It may be that the classifier did not classify accurately enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    # fig = plt.figure()\n",
    "    size = len(dataloaders['test'].dataset)\n",
    "    no_batches = len(dataloaders['test'])\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, anchor_label) in enumerate(dataloaders['test']):\n",
    "\n",
    "            anchor_label = anchor_label.to(device)\n",
    "            \n",
    "            anchor_img, _, _ = inputs\n",
    "            anchor_img = anchor_img.to(device)\n",
    "            \n",
    "        \n",
    "            anchor_out = model(anchor_img)\n",
    "\n",
    "            _, preds = torch.max(anchor_out, 1)\n",
    "\n",
    "            preds = preds.to(device)\n",
    "\n",
    "            correct += torch.sum(preds == anchor_label.data)\n",
    "            if i % 20 == 0:\n",
    "                print(f'Predicted: {preds[0]} | True: {anchor_label[0]}')\n",
    "\n",
    "    correct = correct.double() / size\n",
    "    model.train(mode=was_training)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_acc = test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Acc: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
